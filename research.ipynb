{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c5f00c9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\codes\\transformer\\venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "d:\\codes\\transformer\\venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Suyash\\.cache\\huggingface\\hub\\datasets--sharad461--ne-en-parallel-208k. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 208831/208831 [00:00<00:00, 508105.79 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset, concatenate_datasets\n",
    "\n",
    "ds = load_dataset(\"sharad461/ne-en-parallel-208k\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7c4ebb83",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = ds[\"train\"]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a1a7d127",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ne': ['दाऊदले अमालेकीहरूलाई हराएर पछि सिकलग गए। यो शाऊलको मृत्यु भएको केही दिन पछिको कुरा हो। दाऊद त्यहाँ दुइ दिन बसे।',\n",
       "  'तब तेस्रो दिनमा एउटा जवान सैनिक सिकलगमा आयो। त्यो मानिस शाऊलको छाउनीबाट आएको थियो। त्यसका लुगाहरू च्यतिएको र शिरमा मैला लागेको थियो। त्यसले दाऊदको अघि धोप्टो परेर उनलाई सम्मान गर्न दण्डवत् गर्यो।',\n",
       "  'दाऊदले त्यसलाई सोधे, “तिमी कहाँबाट आयौ?” त्यस मानिसले जवाफ दियो, “म इस्राएली पालबाट आउँदैछु।”',\n",
       "  'दाऊदले भने, “मलाई भन, के भयो?” त्यसले भन्यो, “हाम्रा सबै सैनिकहरू भागे। धेरै मानिसहरू मारिए। शाऊल र तिनका छोरा जोनाथन पनि मरे।”',\n",
       "  'दाऊदले त्यस सैनिकलाई भने, “तिमीले कसरी जान्यौ शाऊल र जोनाथन मरेको कुरा?”',\n",
       "  'त्यो सैनिकले उत्तर दियो, “म गिल्बो पर्वतमाथि थिएँ। मैले शाऊललाई आफ्नो भालामा झुकेको देखें। पलिश्ती सैनिकहरू घोडा र रथहरूमा चढेर शाऊलको नजिक आउँदै थिए।',\n",
       "  'शाऊल वरिपरि घुमे अनि मलाई देखे र उनले मलाई बोलाए।'],\n",
       " 'en': ['It happened after the death of Saul, when David was returned from the slaughter of the Amalekites, and David had stayed two days in Ziklag;',\n",
       "  'it happened on the third day, that behold, a man came out of the camp from Saul, with his clothes torn, and earth on his head: and so it was, when he came to David, that he fell to the earth, and showed respect.',\n",
       "  'David said to him, \"Where do you come from?\" He said to him, \"I have escaped out of the camp of Israel.\"',\n",
       "  'David said to him, \"How did it go? Please tell me.\" He answered, \"The people have fled from the battle, and many of the people also have fallen and are dead; and Saul and Jonathan his son are dead also.\"',\n",
       "  'David said to the young man who told him, \"How do you know that Saul and Jonathan his son are dead?\"',\n",
       "  'The young man who told him said, \"As I happened by chance on Mount Gilboa, behold, Saul was leaning on his spear; and behold, the chariots and the horsemen followed hard after him.',\n",
       "  \"When he looked behind him, he saw me, and called to me. I answered, 'Here I am.'\"]}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset[:7]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d595b868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0],\n",
       "         [1, 1, 0],\n",
       "         [1, 1, 1]]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83e26895",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 16%|█▌        | 32900/208831 [00:16<01:18, 2254.99it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (708 > 512). Running this sequence through the model will result in indexing errors\n",
      " 31%|███▏      | 65668/208831 [00:26<00:37, 3787.61it/s]Token indices sequence length is longer than the specified maximum sequence length for this model (597 > 512). Running this sequence through the model will result in indexing errors\n",
      "100%|██████████| 208831/208831 [01:28<00:00, 2372.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Max source (Nepali) token length: 1569\n",
      "Max target (English) token length: 607\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "# Example: using multilingual BERT (change to your actual model)\n",
    "tokenizer_src = AutoTokenizer.from_pretrained(\"bert-base-multilingual-cased\")\n",
    "tokenizer_tgt = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "max_len_src = 0\n",
    "max_len_tgt = 0\n",
    "\n",
    "for example in tqdm(dataset):\n",
    "    src_text = example['ne']\n",
    "    tgt_text = example['en']\n",
    "\n",
    "    src_ids = tokenizer_src.encode(src_text, add_special_tokens=True)\n",
    "    tgt_ids = tokenizer_tgt.encode(tgt_text, add_special_tokens=True)\n",
    "\n",
    "    max_len_src = max(max_len_src, len(src_ids))\n",
    "    max_len_tgt = max(max_len_tgt, len(tgt_ids))\n",
    "\n",
    "print(f\"Max source (Nepali) token length: {max_len_src}\")\n",
    "print(f\"Max target (English) token length: {max_len_tgt}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4ba337",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
